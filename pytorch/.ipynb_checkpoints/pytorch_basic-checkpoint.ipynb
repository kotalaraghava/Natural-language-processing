{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-math.pi, math.pi, 2000)\n",
    "y = np.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-3.14159265, -3.13844949, -3.13530633, ...,  3.13530633,\n",
       "         3.13844949,  3.14159265]),\n",
       " (2000,),\n",
       " (2000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn()\n",
    "b = np.random.randn()\n",
    "c = np.random.randn()\n",
    "d = np.random.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 3414.0000637180647\n",
      "199 2295.35263135234\n",
      "Results: y = -0.7717203336888667 + -0.431037286382271x + 0.13313460820615472x^2+0.0898448358039112x^3\n"
     ]
    }
   ],
   "source": [
    "for t in range(200):\n",
    "#     print(t)\n",
    "    y_pred = a+b*x+c*x**2+d*x**3\n",
    "    \n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    \n",
    "    if t%100 == 99:\n",
    "        print(t, loss)\n",
    "    \n",
    "    grad_y_pred = 2.0*(y_pred-y)\n",
    "    \n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "    \n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "    \n",
    "print(f'Results: y = {a} + {b}x + {c}x^2+{d}x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "99 % 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "dtype = torch.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Size([2000]), torch.Size([2000]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x), x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn((), device=device, dtype=dtype, requires_grad = True)\n",
    "b = torch.randn((), device=device, dtype=dtype, requires_grad = True)\n",
    "c = torch.randn((), device=device, dtype=dtype, requires_grad = True)\n",
    "d = torch.randn((), device=device, dtype=dtype, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 tensor(63394.6992, grad_fn=<SumBackward0>)\n",
      "199 tensor(104852.0625, grad_fn=<SumBackward0>)\n",
      "299 tensor(43428.5859, grad_fn=<SumBackward0>)\n",
      "399 tensor(86801.5234, grad_fn=<SumBackward0>)\n",
      "499 tensor(25483.4883, grad_fn=<SumBackward0>)\n",
      "599 tensor(62461.6602, grad_fn=<SumBackward0>)\n",
      "699 tensor(15263.6777, grad_fn=<SumBackward0>)\n",
      "799 tensor(42625.2617, grad_fn=<SumBackward0>)\n",
      "899 tensor(20206.1074, grad_fn=<SumBackward0>)\n",
      "999 tensor(31638.0156, grad_fn=<SumBackward0>)\n",
      "1099 tensor(41114.6641, grad_fn=<SumBackward0>)\n",
      "1199 tensor(33504.0469, grad_fn=<SumBackward0>)\n",
      "1299 tensor(69373.7891, grad_fn=<SumBackward0>)\n",
      "1399 tensor(44823.1641, grad_fn=<SumBackward0>)\n",
      "1499 tensor(97262.4375, grad_fn=<SumBackward0>)\n",
      "1599 tensor(56411.7500, grad_fn=<SumBackward0>)\n",
      "1699 tensor(114052.3984, grad_fn=<SumBackward0>)\n",
      "1799 tensor(64220.4570, grad_fn=<SumBackward0>)\n",
      "1899 tensor(111358.0547, grad_fn=<SumBackward0>)\n",
      "1999 tensor(64031.6680, grad_fn=<SumBackward0>)\n",
      "Result f = 0.8448341488838196+-0.2297033965587616*x+-1.1840764284133911*x^2+-0.11951492726802826*x^3\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    \n",
    "    y_pred = a+b*x+c*x**2+d*x**3\n",
    "    \n",
    "    loss = (y_pred-y).pow(2).sum()\n",
    "    if t% 100 == 99:\n",
    "        print(t, loss)\n",
    "#     grad_y_pred = 2.0*(y_pred-y)\n",
    "    loss.backward()\n",
    "#     grad_a = grad_y_pred.sum()\n",
    "#     grad_b = (grad_y_pred * x).sum()\n",
    "#     grad_c = (grad_y_pred * x ** 2).sum()\n",
    "#     grad_d = (grad_y_pred * x ** 3).sum()\n",
    "    with torch.no_grad():\n",
    "        a -= learning_rate * a.grad\n",
    "        b -= learning_rate * b.grad\n",
    "        c -= learning_rate * c.grad\n",
    "        d -= learning_rate * d.grad\n",
    "    \n",
    "    \n",
    "print(f'Result f = {a}+{b}*x+{c}*x^2+{d}*x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegendrePolynomial3(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \n",
    "        ctx.save_for_backward(input)\n",
    "        return 0.5*(5*input**3 - 3*input)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \n",
    "        input,  = ctx.saved_tensors\n",
    "        return grad_output * 1.5 * (5 * input **2 -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 439.35931396484375\n",
      "199 437.4896545410156\n",
      "299 435.80694580078125\n",
      "399 434.2837219238281\n",
      "499 432.8973388671875\n",
      "599 431.6296691894531\n",
      "699 430.4652404785156\n",
      "799 429.391845703125\n",
      "899 428.39825439453125\n",
      "999 427.4754943847656\n",
      "1099 426.6161193847656\n",
      "1199 425.8133544921875\n",
      "1299 425.06146240234375\n",
      "1399 424.35565185546875\n",
      "1499 423.69110107421875\n",
      "1599 423.064697265625\n",
      "1699 422.47259521484375\n",
      "1799 421.9120788574219\n",
      "1899 421.3804016113281\n",
      "1999 420.87542724609375\n",
      "Result: y = -0.618481457233429 + -0.4685993492603302 * P3(-1.022571325302124 + -0.09171546995639801 x)\n"
     ]
    }
   ],
   "source": [
    "for t in range(2000):\n",
    "    \n",
    "    P3 = LegendrePolynomial3.apply\n",
    "    \n",
    "    y_pred = a + b * P3(c+d*x)\n",
    "    \n",
    "    loss = (y_pred-y).pow(2).sum()\n",
    "    \n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "        \n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        a -= learning_rate * a.grad\n",
    "        b -= learning_rate * b.grad\n",
    "        c -= learning_rate * c.grad\n",
    "        d -= learning_rate * d.grad\n",
    "        \n",
    "        a.grad = None\n",
    "        b.grad = None\n",
    "        c.grad = None\n",
    "        d.grad = None\n",
    "        \n",
    "print(f'Result: y = {a.item()} + {b.item()} * P3({c.item()} + {d.item()} x)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -3.1416,   9.8696, -31.0063],\n",
       "        [ -3.1384,   9.8499, -30.9133],\n",
       "        [ -3.1353,   9.8301, -30.8205],\n",
       "        ...,\n",
       "        [  3.1353,   9.8301,  30.8205],\n",
       "        [  3.1384,   9.8499,  30.9133],\n",
       "        [  3.1416,   9.8696,  31.0063]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.linspace(-math.pi, math.pi, 2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "p = torch.tensor([1, 2, 3])\n",
    "xx = x.unsqueeze(-1).pow(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2000]),\n",
       " tensor([[ -3.1416,   9.8696, -31.0063],\n",
       "         [ -3.1384,   9.8499, -30.9133],\n",
       "         [ -3.1353,   9.8301, -30.8205],\n",
       "         ...,\n",
       "         [  3.1353,   9.8301,  30.8205],\n",
       "         [  3.1384,   9.8499,  30.9133],\n",
       "         [  3.1416,   9.8696,  31.0063]]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, x.unsqueeze(-1).pow(torch.tensor([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 tensor(233.2124, grad_fn=<MseLossBackward>)\n",
      "199 tensor(161.6628, grad_fn=<MseLossBackward>)\n",
      "299 tensor(113.0458, grad_fn=<MseLossBackward>)\n",
      "399 tensor(79.9742, grad_fn=<MseLossBackward>)\n",
      "499 tensor(57.4520, grad_fn=<MseLossBackward>)\n",
      "599 tensor(42.0965, grad_fn=<MseLossBackward>)\n",
      "699 tensor(31.6154, grad_fn=<MseLossBackward>)\n",
      "799 tensor(24.4532, grad_fn=<MseLossBackward>)\n",
      "899 tensor(19.5532, grad_fn=<MseLossBackward>)\n",
      "999 tensor(16.1971, grad_fn=<MseLossBackward>)\n",
      "1099 tensor(13.8959, grad_fn=<MseLossBackward>)\n",
      "1199 tensor(12.3161, grad_fn=<MseLossBackward>)\n",
      "1299 tensor(11.2303, grad_fn=<MseLossBackward>)\n",
      "1399 tensor(10.4833, grad_fn=<MseLossBackward>)\n",
      "1499 tensor(9.9687, grad_fn=<MseLossBackward>)\n",
      "1599 tensor(9.6139, grad_fn=<MseLossBackward>)\n",
      "1699 tensor(9.3690, grad_fn=<MseLossBackward>)\n",
      "1799 tensor(9.1997, grad_fn=<MseLossBackward>)\n",
      "1899 tensor(9.0826, grad_fn=<MseLossBackward>)\n",
      "1999 tensor(9.0015, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Sequential(torch.nn.Linear(3, 1),\n",
    "                           torch.nn.Flatten(0, 1)\n",
    "                           )\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-6\n",
    "\n",
    "for t in range(2000):\n",
    "    \n",
    "    y_pred = model(xx)\n",
    "    \n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "    model.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate*param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: y = -0.012291478924453259 + 0.8499004244804382 x + 0.0021204836666584015 x^2 + -0.09235739707946777 x^3\n"
     ]
    }
   ],
   "source": [
    "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(torch.nn.Linear(3, 1),\n",
    "                           torch.nn.Flatten(0, 1))\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(2000):\n",
    "    \n",
    "    y_pred = model(xx)\n",
    "    \n",
    "    loss = loss_fn(y_pred,y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
