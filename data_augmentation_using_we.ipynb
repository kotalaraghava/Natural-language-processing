{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tokenizer(texts):\n",
    "    from keras.preprocessing.text import Tokenizer\n",
    "    t = Tokenizer()\n",
    "    t.fit_on_texts(texts)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['i want to create ecci',\n",
    "        'i want ecci',\n",
    "        'generate ecci',\n",
    "        'create ami',\n",
    "        'generate ami']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = make_tokenizer(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenize.texts_to_sequences(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X = pad_sequences(X, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 2, 3, 7, 4, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 2, 3, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 5, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 4, 6],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 5, 6]], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word = {}\n",
    "for word, index in tokenize.word_index.items():\n",
    "    index_word[index] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'ecci', 2: 'i', 3: 'want', 4: 'create', 5: 'generate', 6: 'ami', 7: 'to'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(index_word.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ecci', 'i', 'want', 'create', 'generate', 'ami', 'to']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(word):\n",
    "     by_similarity = sorted(word.vocab, key=lambda w: word.similarity(w), reverse=True)\n",
    "     return [w.orth_ for w in by_similarity[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/achint/Raghava/pm4py_sources/venv/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['create', 'can', 'Can', 'Need', 'need', 'how', 'How', 'Could', 'could', 'You']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(nlp(\"create\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(word):\n",
    "   queries = [w for w in word.vocab if w.is_lower == word.is_lower\n",
    "             and ]\n",
    "   by_similarity = sorted(queries, key=lambda w: word.similarity(w), reverse=True)\n",
    "   return by_similarity[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/achint/Raghava/pm4py_sources/venv/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: [W008] Evaluating Lexeme.similarity based on empty vectors.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['create',\n",
       " 'can',\n",
       " 'need',\n",
       " 'how',\n",
       " 'could',\n",
       " 'you',\n",
       " 'that',\n",
       " 'these',\n",
       " 'it',\n",
       " 'would']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.lower_ for w in most_similar(nlp.vocab['create'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
