{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipelines\n",
    "This is very powerful class has made my entire ML workflow -- from preprocessing to evaluation -- so much more tractable, more robust, and less susceptible to guesswork, especially in the huperparameter tuning stage. As a colleague of mine said, it really ought to be part of every skelarn-based ML project! Here's a description of waht it does:\n",
    "\n",
    "# Basics \n",
    "\n",
    "Transformer in scikit-learn -- some class that have fit and transform method, or fit_transform method.\n",
    "\n",
    "predictor -- some class that has fit and predict methods, or fit_predict method.\n",
    "\n",
    "pipeline -- is just an abstract notion, its not some existing ML algorithm. often in ML tasks you need to perform sequence of different transformations(find set of features, generate new features, select only some good features) of raw dataset before applying final estimator.\n",
    "\n",
    "sequentially apply a list of transforms and a final estimator. Intermediate steps of the pipeline must be 'transforms', that is, they must implement fit and transform methods. The final estimator only needs to implement fit.\n",
    "\n",
    "\n",
    "### Transformer \n",
    "for data preparation\n",
    "fit -- find parameters from training data(if needed)\n",
    "transform -- apply to training or test data.\n",
    "\n",
    "### Estimator\n",
    "for modeling\n",
    "fit -- find parameters from training data\n",
    "predict -- apply to training or test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpacyVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, nlp):\n",
    "        self.nlp = nlp\n",
    "        self.dim = 300\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [self.nlp(text).vector for text in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['X1', 'X2', 'y'], data=[\n",
    "    [1,16,9],\n",
    "    [4,36,16],\n",
    "    [1,16,9],\n",
    "    [2,9,8],\n",
    "    [3,36,15],\n",
    "    [2,49,16],\n",
    "    [4,25,14],\n",
    "    [5,36,17]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.iloc[:6]\n",
    "test = df.iloc[6:]\n",
    "\n",
    "train_X = train.drop('y', axis=1)\n",
    "train_y = train.y\n",
    "\n",
    "test_X = test.drop('y', axis=1)\n",
    "test_y = test.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.72113586 16.93334467]\n",
      "0.20274138822160603\n"
     ]
    }
   ],
   "source": [
    "m1 = LinearRegression()\n",
    "fit1 = m1.fit(train_X, train_y)\n",
    "preds = fit1.predict(test_X)\n",
    "print(preds)\n",
    "print(np.sqrt(mean_squared_error(test_y, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X1    X2\n",
      "6   4  10.0\n",
      "7   5  12.0\n",
      "[14. 17.]\n",
      "1.2560739669470201e-15\n"
     ]
    }
   ],
   "source": [
    "train_X.X2 = 2 * np.sqrt(train_X.X2)\n",
    "test_X.X2 = 2 * np.sqrt(test_X.X2)\n",
    "\n",
    "print(test_X)\n",
    "m2 = LinearRegression()\n",
    "fit2 = m2.fit(train_X, train_y)\n",
    "preds = fit2.predict(test_X)\n",
    "print(preds)\n",
    "print(np.sqrt(mean_squared_error(test_y, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create pipeline 1\n",
      "fit pipeline 1\n",
      "predict via pipeline 1\n",
      "[13.72113586 16.93334467]\n",
      "0.20274138822160603\n"
     ]
    }
   ],
   "source": [
    "print(\"create pipeline 1\")\n",
    "pipe1 = Pipeline(steps = [\n",
    "    ('linear_model', LinearRegression())\n",
    "])\n",
    "print(\"fit pipeline 1\")\n",
    "pipe1.fit(train_X, train_y)\n",
    "print(\"predict via pipeline 1\")\n",
    "preds1 = pipe1.predict(test_X)\n",
    "print(preds1)\n",
    "print(np.sqrt(mean_squared_error(test_y, preds1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentalTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __inti__(self):\n",
    "        print(' >>>>>>>init() called.\\n')\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        print('>>>>>fit() called .\\n')\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        print('>>>>>transform() called.\\n')\n",
    "        X_ = X.copy() # creating a copy to avoid changes to original dataset\n",
    "        X_.X2 = 2 * np.sqrt(X_.X2)\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created pipeline 2\n",
      "Fit pipeline 2\n",
      ">>>>>fit() called .\n",
      "\n",
      ">>>>>transform() called.\n",
      "\n",
      "predict via pieline 2\n",
      ">>>>>transform() called.\n",
      "\n",
      "[14. 17.]\n",
      "1.2560739669470201e-15\n"
     ]
    }
   ],
   "source": [
    "print(\"Created pipeline 2\")\n",
    "pip2 = Pipeline(steps = [\n",
    "    (\"experimental_trans\", ExperimentalTransformer()),\n",
    "    ('linear_model', LinearRegression())\n",
    "])\n",
    "\n",
    "print(\"Fit pipeline 2\")\n",
    "pip2.fit(train_X, train_y)\n",
    "print(\"predict via pieline 2\")\n",
    "preds2 = pip2.predict(test_X)\n",
    "print(preds2)\n",
    "print(np.sqrt(mean_squared_error(test_y, preds2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentalTransformer_2(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_name, additional_param = \"Himanshu\"):\n",
    "        print(' >>>>>>>init() called.\\n')\n",
    "        self.feature_name = feature_name\n",
    "        self.additional_param = additional_param\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        print('>>>>>fit() called .\\n')\n",
    "        print('additional param ~~~~~')\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        print('>>>>>transform() called.\\n')\n",
    "        X_ = X.copy() # creating a copy to avoid changes to original dataset\n",
    "        X_[self.feature_name] = 2 * np.sqrt(X_[self.feature_name])\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >>>>>>>init() called.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExperimentalTransformer_2(additional_param='Himanshu', feature_name='X2')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExperimentalTransformer_2('X2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create pipeline 2\n",
      " >>>>>>>init() called.\n",
      "\n",
      "Fit pipeline 2\n",
      ">>>>>fit() called .\n",
      "\n",
      "additional param ~~~~~\n",
      ">>>>>transform() called.\n",
      "\n",
      "predict via pipeline 2\n",
      ">>>>>transform() called.\n",
      "\n",
      "[14. 17.]\n",
      "1.2560739669470201e-15\n"
     ]
    }
   ],
   "source": [
    "print(\"create pipeline 2\")\n",
    "pipe2 = Pipeline(steps = [\n",
    "    ('experimental_trans', ExperimentalTransformer_2('X2')),\n",
    "    ('linear_model', LinearRegression())\n",
    "])\n",
    "print(\"Fit pipeline 2\")\n",
    "pipe2.fit(train_X, train_y)\n",
    "print(\"predict via pipeline 2\")\n",
    "preds2 = pipe2.predict(test_X)\n",
    "print(preds2)\n",
    "print(np.sqrt(mean_squared_error(test_y, preds2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
